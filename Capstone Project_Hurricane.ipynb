{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as t\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# all_etl contaisn methods used to initiate the spark session\n",
    "# hurdat_etl and nexrad_etl contain the ETL steps necessary to process and QC the HURDAT and NEXRAD data\n",
    "from all_etl import *\n",
    "from hurdat_etl import *\n",
    "from nexrad_etl import *\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use?\n",
    "\n",
    "This data can be used for historic reconstruction of hurricanes. This would be used in the underlying database for analytics and developing tropical weather models.\n",
    "\n",
    "The data is spatially and temporally indexed, so a user can retrieve records within a given space and time window. \n",
    "\n",
    "The main tools I used are Spark for data processing, ARM's pyart package to process radar files, and SidewalkLabs/Google's S2 package for spatial indexing.\n",
    "\n",
    "https://medium.com/@ligz/installing-standalone-spark-on-windows-made-easy-with-powershell-7f7309799bc7\n",
    "https://arm-doe.github.io/pyart/\n",
    "https://www.sidewalklabs.com/blog/s2-cells-and-space-filling-curves-keys-to-building-better-digital-map-tools-for-cities/\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "HURDAT\n",
    "NOAA's Hurricane Research Division maintains the HURDAT project which analyzes tropical storm tracks and strengths. The data includes the geographic position of each storm at 6-hour intervals. This data includes wind speed and air pressure for the storm at each of these readings.\n",
    "\n",
    "At the time of this project, the HURDAT database includes about 52 thousand rows (storm track points).\n",
    "\n",
    "https://www.aoml.noaa.gov/hrd/data_sub/re_anal.html\n",
    "\n",
    "NEXRAD\n",
    "The National Weather Servive operates NEXRAD Dopplar Radar stations across the US, which operate continuously through the day. The primary products of Dopplar Radar measurements are the reflectivity and velocity of the atmosphere.\n",
    "\n",
    "A single NEXRAD file contains 11 million records, representing reflecivity/ velocity measurements for one radar station at one point in time. Thousands of NEXRAD files are generated per day, so this project only uses a single file for proof of concept.\n",
    "\n",
    "https://www.ncdc.noaa.gov/data-access/radar-data/noaa-big-data-project\n",
    "https://s3.amazonaws.com/noaa-nexrad-level2/index.html\n",
    "https://www.nsstc.uah.edu/users/brian.freitag/AWS_Radar_with_Python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "HURDAT\n",
    "        data is convoluted with header rows interspersed within table\n",
    "\n",
    "NEXRAD\n",
    "    data in az-el, rather than lat lon\n",
    "    data is in a 6480 by 1832 matrix, and needs to be reshaped\n",
    "    sparse data set, only records value if refl / velo to record\n",
    "    data time stamps index off of start time, start time embedded in text and needs to be extracted\n",
    "\n",
    "\n",
    "    \n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "\n",
    "   transform coordinate system from polar to grid\n",
    "   converted lat / lon to S2 cell\n",
    "   reshaped data\n",
    "   flagged header rows, and iterated over table to associate child rows with parent row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "HURDAT\n",
    "    fact table: track point: windspeeds, pressure, lat, lon, S2 cell, time, storm\n",
    "    dim table: storm: storm info\n",
    "    dim table: spatial: S2 cell, centroid, parent cell\n",
    "    dim table: time: datetime heirarchy\n",
    "\n",
    "NEXRAD\n",
    "    fact table: sample: reflectivity, velocity, lat, lon, S2 cell, alt, time, station\n",
    "    dim table: station: station info    \n",
    "    dim table: spatial: S2 cell, centroid, parent cell\n",
    "    dim table: time: datetime heirarchy\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
